#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import os
import sys
import json
import re
from datetime import datetime
from collections import Counter

# Fix Windows console encoding
if sys.platform == 'win32':
    sys.stdout.reconfigure(encoding='utf-8')

def analyze_tweets_for_investments(json_file):
    """Analizuje tweety T_Smolarek pod kÄ…tem inwestycji"""

    print("="*80)
    print("ANALIZA INWESTYCYJNA TWEETÃ“W T_SMOLAREK")
    print("="*80)

    # Load tweets
    with open(json_file, 'r', encoding='utf-8') as f:
        data = json.load(f)

    tweets = data.get('tweets', [])
    print(f"\nAnalizujÄ™ {len(tweets)} tweetÃ³w...\n")

    # 1. Extract stock tickers mentioned
    ticker_pattern = r'\$([A-Z]{1,5})'
    companies_mentioned = Counter()
    ticker_contexts = {}

    # 2. Topic analysis
    topics = {
        'AI': [],
        'Semiconductors': [],
        'Geopolitics': [],
        'China': [],
        'USA': [],
        'Europe': [],
        'Supply Chain': [],
        'Manufacturing': []
    }

    # 3. Companies and keywords
    company_keywords = {
        'NVIDIA': ['nvidia', '$nvda'],
        'ASML': ['asml'],
        'TSMC': ['tsmc', '$tsm'],
        'AMD': ['amd', '$amd'],
        'Intel': ['intel', '$intc'],
        'Qualcomm': ['qualcomm', '$qcom'],
        'Broadcom': ['broadcom', '$avgo'],
        'Applied Materials': ['applied materials', '$amat'],
        'Lam Research': ['lam research', '$lrcx'],
        'KLA': ['kla', '$klac'],
        'Synopsys': ['synopsys', '$snps'],
        'Cadence': ['cadence', '$cdns']
    }

    # 4. Sentiment indicators
    positive_indicators = ['wzrost', 'szansa', 'potencjaÅ‚', 'pozytywn', 'dobrze', 'sukces', 'zysk']
    negative_indicators = ['ryzyko', 'zagroÅ¼enie', 'problem', 'spadek', 'kryzys', 'sÅ‚abo']

    sentiment_scores = {}

    # Analyze each tweet
    for i, tweet in enumerate(tweets, 1):
        text = tweet.get('text', '')
        text_lower = text.lower()
        created_at = tweet.get('createdAt', 'N/A')

        # Extract tickers
        tickers = re.findall(ticker_pattern, text)
        for ticker in tickers:
            companies_mentioned[ticker] += 1
            if ticker not in ticker_contexts:
                ticker_contexts[ticker] = []
            ticker_contexts[ticker].append({
                'date': created_at,
                'text': text[:200],
                'likes': tweet.get('likeCount', 0),
                'views': tweet.get('viewCount', 0)
            })

        # Company mentions
        for company, keywords in company_keywords.items():
            if any(kw in text_lower for kw in keywords):
                companies_mentioned[company] += 1
                if company not in ticker_contexts:
                    ticker_contexts[company] = []
                ticker_contexts[company].append({
                    'date': created_at,
                    'text': text[:300],
                    'likes': tweet.get('likeCount', 0),
                    'views': tweet.get('viewCount', 0)
                })

        # Topic classification
        if any(word in text_lower for word in [' ai ', 'ai,', 'ai.', 'sztuczn', 'artificial']):
            topics['AI'].append(text[:200])

        if any(word in text_lower for word in ['chip', 'pÃ³Å‚przewodnik', 'semiconductor', 'wafer', 'litograf']):
            topics['Semiconductors'].append(text[:200])

        if any(word in text_lower for word in ['chin', 'ðŸ‡¨ðŸ‡³', 'pekin']):
            topics['China'].append(text[:200])

        if any(word in text_lower for word in ['usa', 'ðŸ‡ºðŸ‡¸', 'ameryk', 'waszyngton']):
            topics['USA'].append(text[:200])

        if any(word in text_lower for word in ['europ', 'ðŸ‡ªðŸ‡º', 'ue ', 'unii', 'bruksela']):
            topics['Europe'].append(text[:200])

        if any(word in text_lower for word in ['geopolit', 'handel', 'restrykcj', 'sankcj', 'wojna handlowa']):
            topics['Geopolitics'].append(text[:200])

        if any(word in text_lower for word in ['Å‚aÅ„cuch dostaw', 'supply chain', 'produkcj', 'fabryka', 'manufacturing']):
            topics['Supply Chain'].append(text[:200])

    # Print analysis
    print("\n" + "="*80)
    print("1. NAJCZÄ˜ÅšCIEJ WSPOMNIANE SPÃ“ÅKI")
    print("="*80)

    for company, count in companies_mentioned.most_common(15):
        print(f"\n{company}: {count} wzmianek")

        if company in ticker_contexts and ticker_contexts[company]:
            latest = ticker_contexts[company][0]
            total_views = sum(ctx.get('views', 0) for ctx in ticker_contexts[company])
            total_likes = sum(ctx.get('likes', 0) for ctx in ticker_contexts[company])

            print(f"  ÅÄ…czne wyÅ›wietlenia: {total_views:,}")
            print(f"  ÅÄ…czne polubienia: {total_likes:,}")
            print(f"  Ostatnia wzmianka: {latest['date']}")
            print(f"  Kontekst: {latest['text'][:150]}...")

    print("\n" + "="*80)
    print("2. ANALIZA TEMATYCZNA")
    print("="*80)

    for topic, mentions in topics.items():
        if mentions:
            print(f"\n{topic}: {len(mentions)} tweetÃ³w")

    print("\n" + "="*80)
    print("3. KLUCZOWE WNIOSKI Z ANALIZY")
    print("="*80)

    # Analyze full text for key themes
    full_text = ' '.join([t.get('text', '') for t in tweets]).lower()

    print("\nGÅ‚Ã³wne tezy autora:")

    if 'asml' in full_text and 'euv' in full_text:
        print("\nâœ“ ASML i technologia EUV:")
        print("  - PodkreÅ›la technologicznÄ… dominacjÄ™ ASML w litografii EUV")
        print("  - Zachodnia inÅ¼ynieria na najwyÅ¼szym poziomie")
        print("  - WspÃ³Å‚praca krajÃ³w zachodnich (NL, USA, DE, UK)")

    if 'chin' in full_text and any(word in full_text for word in ['dominuj', 'zagroÅ¼en', 'bezpieczeÅ„']):
        print("\nâš ï¸ ZagroÅ¼enia z Chin:")
        print("  - UzaleÅ¼nienie od chiÅ„skich dostaw (metale ziem rzadkich, proste chipy)")
        print("  - Ryzyko geopolityczne i weaponizacja Å‚aÅ„cuchÃ³w dostaw")
        print("  - Potrzeba dywersyfikacji i onshoring'u")

    if 'nvidia' in full_text:
        print("\nâœ“ NVIDIA:")
        print("  - Lider w AI chips")
        print("  - Atrakcyjna wycena na PEG")
        print("  - Silny popyt przekraczajÄ…cy podaÅ¼")

    if 'bezpieczeÅ„st' in full_text and 'gospodar' in full_text:
        print("\nâœ“ BezpieczeÅ„stwo gospodarcze:")
        print("  - BezpieczeÅ„stwo gospodarcze = bezpieczeÅ„stwo narodowe")
        print("  - Krytyka nadmiernej zaleÅ¼noÅ›ci od Chin")
        print("  - Potrzeba budowy wÅ‚asnych zdolnoÅ›ci produkcyjnych")

    # Generate investment recommendations
    print("\n" + "="*80)
    print("4. REKOMENDACJE INWESTYCYJNE (na podstawie analizy)")
    print("="*80)

    recommendations = []

    # Based on mentions and context
    if companies_mentioned.get('NVIDIA', 0) > 0 or companies_mentioned.get('NVDA', 0) > 0:
        recommendations.append({
            'ticker': '$NVDA',
            'company': 'NVIDIA',
            'rating': 'KUP',
            'rationale': 'Atrakcyjna wycena na PEG, silny popyt na AI chips, pozycja lidera',
            'mentions': companies_mentioned.get('NVIDIA', 0) + companies_mentioned.get('NVDA', 0)
        })

    if companies_mentioned.get('ASML', 0) > 0:
        recommendations.append({
            'ticker': 'ASML',
            'company': 'ASML',
            'rating': 'KUP',
            'rationale': 'Monopol w EUV, niezbÄ™dne dla produkcji zaawansowanych chipÃ³w, wysoka bariera wejÅ›cia',
            'mentions': companies_mentioned.get('ASML', 0)
        })

    if companies_mentioned.get('TSMC', 0) > 0 or companies_mentioned.get('TSM', 0) > 0:
        recommendations.append({
            'ticker': '$TSM',
            'company': 'TSMC',
            'rating': 'KUP',
            'rationale': 'NajwiÄ™kszy foundry Å›wiata, kluczowy gracz w Å‚aÅ„cuchu dostaw chipÃ³w',
            'mentions': companies_mentioned.get('TSMC', 0) + companies_mentioned.get('TSM', 0)
        })

    # Sector recommendations based on themes
    if len(topics['Semiconductors']) > 3:
        recommendations.append({
            'ticker': 'SEKTOR',
            'company': 'Semiconductor Equipment (ASML, AMAT, LRCX, KLAC)',
            'rating': 'KUP',
            'rationale': 'Autor koncentruje siÄ™ na Å‚aÅ„cuchu dostaw pÃ³Å‚przewodnikÃ³w i equipment',
            'mentions': len(topics['Semiconductors'])
        })

    print("\nREKOMENDOWANE SPÃ“ÅKI:")
    for i, rec in enumerate(recommendations, 1):
        print(f"\n{i}. {rec['company']} ({rec['ticker']})")
        print(f"   Rating: {rec['rating']}")
        print(f"   Wzmianki: {rec['mentions']}")
        print(f"   Uzasadnienie: {rec['rationale']}")

    # Additional sector plays based on themes
    print("\n\nDODATKOWE MOÅ»LIWOÅšCI INWESTYCYJNE (wynikajÄ…ce z analiz autora):")

    print("\nðŸ“Š Sektor pÃ³Å‚przewodnikÃ³w (Semiconductor Equipment):")
    print("   â€¢ Applied Materials ($AMAT) - equipment dla produkcji chipÃ³w")
    print("   â€¢ Lam Research ($LRCX) - etching i deposition equipment")
    print("   â€¢ KLA Corporation ($KLAC) - metrologia i inspekcja")

    print("\nðŸ“Š Western Reshoring / Onshoring:")
    print("   â€¢ SpÃ³Å‚ki budujÄ…ce faby w USA/Europie")
    print("   â€¢ Intel ($INTC) - inwestycje w USA i EuropÄ™ (ryzykowne)")
    print("   â€¢ GlobalFoundries ($GFS) - foundry w USA i Europie")

    print("\nâš ï¸ SPÃ“ÅKI DO UNIKANIA (potencjalne ryzyka z analiz):")
    if len(topics['China']) > 2:
        print("   â€¢ ChiÅ„skie spÃ³Å‚ki chipowe - ryzyko geopolityczne, ograniczenia eksportowe")
        print("   â€¢ SpÃ³Å‚ki silnie uzaleÅ¼nione od chiÅ„skiego rynku")

    # Save detailed analysis
    output_file = f"data/analysis/smolarek_investment_analysis_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
    os.makedirs('data/analysis', exist_ok=True)

    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump({
            'analyzed_at': datetime.now().isoformat(),
            'tweets_analyzed': len(tweets),
            'companies_mentioned': dict(companies_mentioned.most_common()),
            'topics': {k: len(v) for k, v in topics.items()},
            'recommendations': recommendations,
            'ticker_contexts': ticker_contexts
        }, f, indent=2, ensure_ascii=False)

    print(f"\n\nâœ“ SzczegÃ³Å‚owa analiza zapisana do: {output_file}")

    return recommendations

if __name__ == "__main__":
    import sys

    if len(sys.argv) > 1:
        json_file = sys.argv[1]
    else:
        # Use the most recent file
        import glob
        files = glob.glob('data/raw/smolarek_all_tweets_*.json')
        if files:
            json_file = max(files)
        else:
            print("Nie znaleziono pliku z tweetami!")
            sys.exit(1)

    print(f"AnalizujÄ™ plik: {json_file}\n")
    analyze_tweets_for_investments(json_file)
